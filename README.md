---

# 🚨 Cyberbullying Recognizer and Summarizer

## 📌 Software and Tools Requirements

1. [GitHub Account](https://github.com) – for version control and project collaboration
2. [VS Code IDE](https://code.visualstudio.com/) – for development and debugging
3. [Git CLI](https://git-scm.com/book/en/v2/Getting-Started-The-Command-Line) – for managing repositories from the command line

---

## 📖 Project Introduction

Cyberbullying is the act of using digital technology to **harass, humiliate, or threaten someone**. It can occur in multiple forms, such as:

* Sending mean or threatening messages
* Spreading false information or rumors
* Posting hurtful images or videos online

### Why is it Important?

Cyberbullying can have **serious and long-lasting effects** on its victims:

* Causes **anxiety, depression, and low self-esteem**
* Victims often feel trapped, as the internet makes harassment harder to escape
* In extreme cases, cyberbullying has been linked to **suicidal behavior**

### Our Solution 🚀

This application is designed to:
✅ **Detect offensive or bullying content** in real-time
✅ **Provide a warning popup** before a user sends potentially harmful messages
✅ **Summarize detected content** for quick review
✅ **Visualize the level of offensiveness** using an **Offensive Meter**

Studies suggest that when users are **warned before sending offensive text**, there is a high chance they will **reconsider and avoid sending it**, helping reduce cyberbullying cases.

---

## ⚙️ Core Functionalities

### 1. Choice Menu

A simple menu that allows users to choose between **summarization, offensive analysis, or both**.

![Choice Menu](https://user-images.githubusercontent.com/86300718/218245622-348575cb-9036-4121-ab08-791d465a74e9.png)

---

### 2. Summarizer

The summarizer extracts the **core meaning** of a conversation or text block, making it easier to review offensive messages quickly.

![Summarizer](https://user-images.githubusercontent.com/86300718/218245629-14ebf7b1-cc55-4a63-9ce3-b342ddd5b2c3.png)

---

### 3. Offensive Meter & Analyzer

* Analyzes text for **toxicity and offensiveness**
* Displays an **offensive score** using a meter
* Helps users understand the **severity of the message**

![Offensive Meter](https://user-images.githubusercontent.com/86300718/218245638-3e0484f5-a409-45b7-ae76-5fe5664dc557.png)

---

👉 Would you like me to also add a **technical workflow diagram (architecture flow)** and a **sample dataset description** section so that the documentation feels more complete for a GitHub project?
